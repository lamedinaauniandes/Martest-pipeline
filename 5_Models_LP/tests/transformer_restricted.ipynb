{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4738d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8cdbc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lamedinaa/testing_rl/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lamedinaa/testing_rl\n",
      "/home/lamedinaa/testing_rl/data/4_random_forest_model/datasets/abstract_episodes_4_combine_khordoo_252106052025.csv\n",
      "/home/lamedinaa/testing_rl/data/2_abstract_classes/abstract_states_4_combine_khordoo_252106052025.json\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import os \n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "base_dir = Path(os.getcwd()).resolve().parent.parent\n",
    "config = configparser.ConfigParser()\n",
    "print(base_dir)\n",
    "config.read(os.path.join(base_dir,'config.ini'))\n",
    "\n",
    "path_file_abstract_datasets = '/home/lamedinaa/testing_rl/data/4_random_forest_model/datasets/abstract_episodes_4_combine_khordoo_252106052025.csv'\n",
    "# path_file_abstract_datasets = '/home/lamedinaa/testing_rl/data/4_random_forest_model/datasets/abstract_episodes_4_combine_kapil_361502052025.csv'\n",
    "# path_file_abstract_datasets = '/home/lamedinaa/testing_rl/data/4_random_forest_model/datasets/abstract_episodes_4_nihal_351905032025.csv'\n",
    "print(path_file_abstract_datasets)\n",
    "\n",
    "path_file_abstract_states = '/home/lamedinaa/testing_rl/data/2_abstract_classes/abstract_states_4_combine_khordoo_252106052025.json'\n",
    "# path_file_abstract_states = '/home/lamedinaa/testing_rl/data/2_abstract_classes/abstract_states_4_combine_kapil_361502052025.json'\n",
    "# path_file_abstract_states = '/home/lamedinaa/testing_rl/data/2_abstract_classes/abstract_states_4_nihal_351905032025.json'\n",
    "print(path_file_abstract_states)\n",
    "\n",
    "f = open(path_file_abstract_states,'r')\n",
    "dict_abstract_states = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a252b3a5",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9390cc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "## definimos el vocabularion\n",
    "especial_words = [\"1\",\"0\",\"2\",\"3\",\"True\",'[UNK]','[BOS]']\n",
    "vocabulary_map = {f'w{i+1}':abstract_class for i,abstract_class in enumerate(dict_abstract_states.keys()) }\n",
    "vocabulary = list(vocabulary_map.keys()) + especial_words \n",
    "## tokenizamos\n",
    "vocab =  {word:idx for idx,word in enumerate(vocabulary)}\n",
    "\n",
    "tokenizer = Tokenizer(WordLevel(vocab,unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b325e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "946"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "754af1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BOS] w384 3 w384 3 w241 3 w397 1 w241 3 w183 3 w346 1 w183 3 w183 3 w346 1 w183 3 w203 0 w203 0 w203 0 w130 0 w130 0 w130 0 w130 0 w242 0 w242 0 w242 0 w242 0 w350 0 w133 2 w133 2 w350 0 w133 2 w133 2 w242 0 w205 2 w242 0 w205 2 w242 0 w133 2 w205 2 w242 0 w133 2 w242 0 w205 2 w205 2 w57 2 w130 0 w57 2 w57 2 w57 2 w203 0 w130 0 w57 2 w57 2 w203 0 w203 0 w57 2 w203 0 w57 2 w57 2 w203 0 w96 2 w217 0 w96 2 w96 2 w217 0 w217 0 w96 2 w346 1 w57 2 w96 2 w217 0 w151 2 w151 2 w131 2 w159 1 w74 0 w151 2 w151 2 w131 2 w31 2 w89 1 w103 0 w131 2 w131 2 w31 2 w118 2 w110 1 w31 2 w81 0 w31 2 w118 2 w118 2 w166 0 w44 2 w44 2 w166 0 w44 2 w53 2 w119 1 w102 0 w53 2 w55 0 w53 2 w16 2 w55 0 w16 2 w99 0 w16 2 w16 2 w16 2 w99 0 w34 1 w99 0 w16 2 w99 0 w147 2 w99 0 w147 2 w34 1 w147 2 w39 2 w132 0 w39 2 w39 2 w168 0 w164 2 w168 0 w164 2 w164 2 w46 0 w28 2 w37 0 w37 0 w28 2 w37 0 w52 2 w37 0 w52 2 w40 2 w141 0 w40 2 w141 0 w40 2 w4 0 w32 2 w32 2 w32 2 w4 0 w32 2 w32 2 w32 2 w85 0 w66 2 w66 2 w66 2 w66 2 w38 0 w72 2 w72 2 w121 0 w180 2 w180 2 w121 0 w180 2 w113 2 w113 2 w12 2 w100 0 w113 2 w70 0 w113 2 w113 2 w113 2 w113 2 w70 0 w113 2 w70 0 w70 0 w113 2 w70 0 w113 2 w113 2 w113 2 w12 2 w70 0 w12 2 w12 2 w113 2 w113 2 w100 0 w113 2 w70 0 w113 2 w12 2 w70 0 w12 2 w12 2 w76 0 w70 0 w12 2 w76 0 w12 2 w11 2 w11 2 w82 0 w11 2 w82 0 w41 2 w82 0 w82 0 w41 2 w82 0 w41 2 w143 0 w41 2 w143 0 w135 2 w143 0 w135 2 w135 2 w347 3 w135 2 w67 0 w135 2 w67 0 w135 2 w143 0 w135 2 w135 2 w67 0 w5 2 w5 2 w277 3 w67 0 w5 2 w91 0 w67 0 w5 2 w5 2 w91 0 w71 2 w71 2 w71 2 w277 3 w91 0 w5 2 w5 2 w5 2 w91 0 w71 2 w91 0 w71 2 w91 0 w71 2 w248 3 w79 0 w71 2 w79 0 w59 2 w59 2 w79 0 w59 2 w7 0 w59 2 w59 2 w1 2 w7 0 w1 2 w1 2 w1 2 w251 3 w134 1 w1 2 w24 2 w21 0 w24 2 w21 0 w24 2 w24 2 w21 0 w24 2 w92 0 w9 2 w92 0 w92 0 w9 2 w92 0 w9 2 w9 2 w9 2 w92 0 w24 2 w92 0 w24 2 w305 1 w24 2 w24 2 w21 0 w24 2 w251 3 w305 1 w24 2 w21 0 w116 3 w49 2 w58 2 w223 3 w13 2 w25 0 w25 0 w25 0 w25 0 w106 0 w106 0 w106 0 w106 0 w106 0 w106 0 w106 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w106 0 w106 0 w106 0 w120 0 w106 0 w30 0 w106 0 w26 0 w87 0 w117 0 w87 0 w117 0 w23 0 True\n",
      "[BOS] w384 3 w384 3 w241 3 w397 1 w241 3 w183 3 w346 1 w183 3 w183 3 w346 1 w183 3 w203 0 w203 0 w203 0 w130 0 w130 0 w130 0 w130 0 w242 0 w242 0 w242 0 w242 0 w350 0 w133 2 w133 2 w350 0 w133 2 w133 2 w242 0 w205 2 w242 0 w205 2 w242 0 w133 2 w205 2 w242 0 w133 2 w242 0 w205 2 w205 2 w57 2 w130 0 w57 2 w57 2 w57 2 w203 0 w130 0 w57 2 w57 2 w203 0 w203 0 w57 2 w203 0 w57 2 w57 2 w203 0 w96 2 w217 0 w96 2 w96 2 w217 0 w217 0 w96 2 w346 1 w57 2 w96 2 w217 0 w151 2 w151 2 w131 2 w159 1 w74 0 w151 2 w151 2 w131 2 w31 2 w89 1 w103 0 w131 2 w131 2 w31 2 w118 2 w110 1 w31 2 w81 0 w31 2 w118 2 w118 2 w166 0 w44 2 w44 2 w166 0 w44 2 w53 2 w119 1 w102 0 w53 2 w55 0 w53 2 w16 2 w55 0 w16 2 w99 0 w16 2 w16 2 w16 2 w99 0 w34 1 w99 0 w16 2 w99 0 w147 2 w99 0 w147 2 w34 1 w147 2 w39 2 w132 0 w39 2 w39 2 w168 0 w164 2 w168 0 w164 2 w164 2 w46 0 w28 2 w37 0 w37 0 w28 2 w37 0 w52 2 w37 0 w52 2 w40 2 w141 0 w40 2 w141 0 w40 2 w4 0 w32 2 w32 2 w32 2 w4 0 w32 2 w32 2 w32 2 w85 0 w66 2 w66 2 w66 2 w66 2 w38 0 w72 2 w72 2 w121 0 w180 2 w180 2 w121 0 w180 2 w113 2 w113 2 w12 2 w100 0 w113 2 w70 0 w113 2 w113 2 w113 2 w113 2 w70 0 w113 2 w70 0 w70 0 w113 2 w70 0 w113 2 w113 2 w113 2 w12 2 w70 0 w12 2 w12 2 w113 2 w113 2 w100 0 w113 2 w70 0 w113 2 w12 2 w70 0 w12 2 w12 2 w76 0 w70 0 w12 2 w76 0 w12 2 w11 2 w11 2 w82 0 w11 2 w82 0 w41 2 w82 0 w82 0 w41 2 w82 0 w41 2 w143 0 w41 2 w143 0 w135 2 w143 0 w135 2 w135 2 w347 3 w135 2 w67 0 w135 2 w67 0 w135 2 w143 0 w135 2 w135 2 w67 0 w5 2 w5 2 w277 3 w67 0 w5 2 w91 0 w67 0 w5 2 w5 2 w91 0 w71 2 w71 2 w71 2 w277 3 w91 0 w5 2 w5 2 w5 2 w91 0 w71 2 w91 0 w71 2 w91 0 w71 2 w248 3 w79 0 w71 2 w79 0 w59 2 w59 2 w79 0 w59 2 w7 0 w59 2 w59 2 w1 2 w7 0 w1 2 w1 2 w1 2 w251 3 w134 1 w1 2 w24 2 w21 0 w24 2 w21 0 w24 2 w24 2 w21 0 w24 2 w92 0 w9 2 w92 0 w92 0 w9 2 w92 0 w9 2 w9 2 w9 2 w92 0 w24 2 w92 0 w24 2 w305 1 w24 2 w24 2 w21 0 w24 2 w251 3 w305 1 w24 2 w21 0 w116 3 w49 2 w58 2 w223 3 w13 2 w25 0 w25 0 w25 0 w25 0 w106 0 w106 0 w106 0 w106 0 w106 0 w106 0 w106 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w30 0 w106 0 w106 0 w106 0 w120 0 w106 0 w30 0 w106 0 w26 0 w87 0 w117 0 w87 0 w117 0 w23 0 True\n"
     ]
    }
   ],
   "source": [
    "#### get and prepare data\n",
    "df_abstract_states = pd.read_csv(path_file_abstract_datasets,sep=';')\n",
    "\n",
    "def clean_text(row):\n",
    "    return '[BOS] '+re.sub(r'\\[\\[.*?\\]\\]', '[UNK]', row['parse_abstract_states']) + ' True'\n",
    "\n",
    "texts = df_abstract_states.apply(clean_text,axis=1)\n",
    "\n",
    "###### CODIFICACIÃ“N DE TEXTOS \n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "fast_tokenizer = PreTrainedTokenizerFast(tokenizer_object = tokenizer)\n",
    "fast_tokenizer.add_special_tokens({\n",
    "    'unk_token': '[UNK]',\n",
    "    'pad_token': '[PAD]',\n",
    "    'bos_token': '[BOS]'\n",
    "})\n",
    "encodings = fast_tokenizer(\n",
    "    list(texts),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True, \n",
    "    max_length=1024, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "def scale(row,min_reward,max_reward):\n",
    "    reward = 200 if row['reward_mean']>200 else row['reward_mean']\n",
    "    reward = 0 if reward<0 else reward\n",
    "    return (reward - min_reward)/(max_reward - min_reward)\n",
    "\n",
    "def scale2(row): \n",
    "    if row['prob_fault']<0: \n",
    "        return 0\n",
    "    if row['prob_fault'] > 1: \n",
    "        return 1        \n",
    "    return row['prob_fault']\n",
    "\n",
    "rewards = df_abstract_states.apply(lambda row: scale(row,0,200),axis=1) ## norm rewards\n",
    "# prob_fault = df_abstract_states['prob_fault']\n",
    "prob_fault = df_abstract_states.apply(scale2,axis=1)\n",
    "\n",
    "######## PRUEBA\n",
    "ids = [int(t) for t in list(encodings['input_ids'][0])]\n",
    "print(tokenizer.decode(ids))\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4436cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in list(encodings['input_ids']): \n",
    "    if t.min().item() <0 or t.max().item()>946: \n",
    "        print(f\"Min: {t.min().item()}, Max: {t.max().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d7ccc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "947"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fast_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "550efc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in list(rewards):\n",
    "    if r<0 or r>1:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2752dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in list(prob_fault):\n",
    "    if p<0 or p>1:\n",
    "        print(p)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1117c2c",
   "metadata": {},
   "source": [
    "## CONDITIONAL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a74640f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CondDataset(Dataset):\n",
    "    def __init__(self, encodings, rewards, probs):\n",
    "        \"\"\"\n",
    "        encodings: dict con 'input_ids' y 'attention_mask' (tensors pt)\n",
    "        rewards:  lista o tensor de floats normalizados en [0,1]\n",
    "        probs:    lista o tensor de floats normalizados en [0,1]\n",
    "        \"\"\"\n",
    "        self.encodings = encodings\n",
    "        self.rewards   = torch.tensor(rewards, dtype=torch.float)\n",
    "        self.probs     = torch.tensor(probs,   dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\":      self.encodings[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n",
    "            \"labels\":         self.encodings[\"input_ids\"][idx],  # causal LM\n",
    "            \"reward\":         self.rewards[idx],\n",
    "            \"prob_fault\":     self.probs[idx],\n",
    "        }\n",
    "\n",
    "\n",
    "dataset = CondDataset(encodings,rewards,prob_fault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd4fc8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([945,  33, 939,  ..., 946, 946, 946]),\n",
       " 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       " 'labels': tensor([945,  33, 939,  ..., 946, 946, 946]),\n",
       " 'reward': tensor(1.),\n",
       " 'prob_fault': tensor(0.0880)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99726f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([945,  33, 939,  ..., 946, 946, 946]),\n",
       " 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       " 'labels': tensor([945,  33, 939,  ..., 946, 946, 946]),\n",
       " 'reward': tensor(1.),\n",
       " 'prob_fault': tensor(0.0880)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa7a822d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([945,  33, 939,  ..., 946, 946, 946])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(1)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e54c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([945,  33, 939,  ..., 946, 946, 946])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(1)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df063241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.__getitem__(1)['input_ids']),len(dataset.__getitem__(1)['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2266b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.__getitem__(1)['input_ids']),len(dataset.__getitem__(1)['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e2c3d",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8da4ac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 02:35:44.963429: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-11 02:35:45.096977: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-11 02:35:45.781346: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-05-11 02:35:45.781408: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-05-11 02:35:45.781413: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import GPT2LMHeadModel, GPT2Config\n",
    "\n",
    "class CondGPT2(GPT2LMHeadModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        d = config.n_embd\n",
    "        self.cond_proj = nn.Sequential(\n",
    "            nn.Linear(2, d),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d, d)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None,\n",
    "                labels=None, reward=None, prob_fault=None, **kwargs):\n",
    "                \n",
    "\n",
    "        print('debug 1')\n",
    "        cond = torch.stack([reward, prob_fault], dim=-1)     \n",
    "        cond_emb = self.cond_proj(cond)                    \n",
    "        print('debug 2')\n",
    "        inputs_embeds = self.transformer.wte(input_ids)    \n",
    "        print('debug 3')\n",
    "        cond_exp = cond_emb.unsqueeze(1).expand_as(inputs_embeds)\n",
    "        inputs_embeds = inputs_embeds + cond_exp\n",
    "        print('debug 4')\n",
    "        return super().forward(\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def prepare_inputs_for_generation(self,\n",
    "            input_ids,\n",
    "            attention_mask=None,\n",
    "            **model_kwargs\n",
    "        ):\n",
    "        # Este mÃ©todo se invoca en cada paso de generate().\n",
    "        # Sacamos reward y prob_fault de model_kwargs\n",
    "        print('debug 5')\n",
    "        return {\n",
    "            \"input_ids\":      input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"reward\":         model_kwargs[\"reward\"],\n",
    "            \"prob_fault\":     model_kwargs[\"prob_fault\"],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed22a61f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b490e7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: min_id=0, max_id=946 dtype=torch.int64\n",
      "Batch 1: min_id=0, max_id=946 dtype=torch.int64\n",
      "Batch 2: min_id=0, max_id=946 dtype=torch.int64\n",
      "Batch 3: min_id=0, max_id=946 dtype=torch.int64\n",
      "Batch 4: min_id=0, max_id=945 dtype=torch.int64\n"
     ]
    }
   ],
   "source": [
    "# DespuÃ©s de model.to(device), pero antes de trainer.train():\n",
    "for i in range(5):\n",
    "    batch = dataset[i]\n",
    "    ids = batch['input_ids']\n",
    "    print(f\"Batch {i}: min_id={ids.min().item()}, max_id={ids.max().item()}\", \n",
    "          f\"dtype={ids.dtype}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "680a064d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token_id = 946\n"
     ]
    }
   ],
   "source": [
    "print(\"pad_token_id =\", fast_tokenizer.pad_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2d15179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='441' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 441/3180 01:21 < 08:29, 5.38 it/s, Epoch 1.38/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n",
      "debug 1\n",
      "debug 2\n",
      "debug 3\n",
      "debug 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 42\u001b[0m\n\u001b[1;32m     25\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     26\u001b[0m     output_dir \u001b[38;5;241m=\u001b[39m save_directory,\n\u001b[1;32m     27\u001b[0m     num_train_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     save_total_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     34\u001b[0m     model \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m     35\u001b[0m     args\u001b[38;5;241m=\u001b[39m training_args, \n\u001b[1;32m     36\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m     37\u001b[0m     data_collator \u001b[38;5;241m=\u001b[39m default_data_collator\n\u001b[1;32m     38\u001b[0m )\n\u001b[0;32m---> 42\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/testing_rl/env/lib/python3.10/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/testing_rl/env/lib/python3.10/site-packages/transformers/trainer.py:2560\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2553\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2554\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2556\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2558\u001b[0m )\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2560\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2563\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2564\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2565\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2566\u001b[0m ):\n\u001b[1;32m   2567\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2568\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/testing_rl/env/lib/python3.10/site-packages/transformers/trainer.py:3782\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   3780\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 3782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3784\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/testing_rl/env/lib/python3.10/site-packages/accelerate/accelerator.py:2454\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2454\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/testing_rl/env/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/testing_rl/env/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, default_data_collator\n",
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "save_directory = '/home/lamedinaa/testing_rl/data/5_models_LP/transformers/gpt2_model3'\n",
    "\n",
    "config = GPT2Config(\n",
    "    vocab_size=len(fast_tokenizer),\n",
    "    n_embd=512,\n",
    "    n_layer=6,\n",
    "    n_head=8,\n",
    "    bos_token_id=fast_tokenizer.pad_token_id,\n",
    "    eos_token_id=fast_tokenizer.pad_token_id,\n",
    "    pad_token_id=fast_tokenizer.pad_token_id\n",
    ")\n",
    "model = CondGPT2(config)\n",
    "model.resize_token_embeddings(len(fast_tokenizer))\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = save_directory,\n",
    "    num_train_epochs = 10,\n",
    "    per_device_train_batch_size =8, \n",
    "    save_steps=500, \n",
    "    save_total_limit=2, \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args= training_args, \n",
    "    train_dataset=dataset,\n",
    "    data_collator = default_data_collator\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029cf1ca",
   "metadata": {},
   "source": [
    "## SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d77c36de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/lamedinaa/testing_rl/data/5_models_LP/prueba/conditional_gpt_models/nihal\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(model_path,exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave_pretrained(model_path)\n\u001b[1;32m      6\u001b[0m fast_tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(model_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_path = '/home/lamedinaa/testing_rl/data/5_models_LP/prueba/conditional_gpt_models/nihal'\n",
    "os.makedirs(model_path,exist_ok=True)\n",
    "model.save_pretrained(model_path)\n",
    "fast_tokenizer.save_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b8dcc3",
   "metadata": {},
   "source": [
    "## PROMPTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0287bbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lamedinaa/testing_rl/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-11 00:20:49.192298: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-11 00:20:49.324557: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-11 00:20:49.977259: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-05-11 00:20:49.977322: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-05-11 00:20:49.977328: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import GPT2LMHeadModel, GPT2Config\n",
    "\n",
    "class CondGPT2(GPT2LMHeadModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        d = config.n_embd\n",
    "        self.cond_proj = nn.Sequential(\n",
    "            nn.Linear(2, d),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d, d)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None,\n",
    "                labels=None, reward=None, prob_fault=None, **kwargs):\n",
    "\n",
    "\n",
    "        cond = torch.stack([reward, prob_fault], dim=-1)     \n",
    "        cond_emb = self.cond_proj(cond)                    \n",
    "\n",
    "        inputs_embeds = self.transformer.wte(input_ids)    \n",
    "\n",
    "        cond_exp = cond_emb.unsqueeze(1).expand_as(inputs_embeds)\n",
    "        inputs_embeds = inputs_embeds + cond_exp\n",
    "        \n",
    "        return super().forward(\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def prepare_inputs_for_generation(self,\n",
    "            input_ids,\n",
    "            attention_mask=None,\n",
    "            **model_kwargs\n",
    "        ):\n",
    "        # Este mÃ©todo se invoca en cada paso de generate().\n",
    "        # Sacamos reward y prob_fault de model_kwargs\n",
    "        return {\n",
    "            \"input_ids\":      input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"reward\":         model_kwargs[\"reward\"],\n",
    "            \"prob_fault\":     model_kwargs[\"prob_fault\"],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c051336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, default_data_collator\n",
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "### nihal\n",
    "# save_dir = '/home/lamedinaa/testing_rl/data/5_models_LP/models/model_condtransformer_4_nihal_351905032025'\n",
    "### nihal\n",
    "# save_dir = '/home/lamedinaa/testing_rl/data/5_models_LP/models/model_condtransformer_4_combine_nihal_291602052025'\n",
    "### kapil\n",
    "save_dir = '/home/lamedinaa/testing_rl/data/5_models_LP/models/model_condtransformer_4_combine_kapil_361502052025'\n",
    "### shakti\n",
    "# save_dir = '/home/lamedinaa/testing_rl/data/5_models_LP/models/model_condtransformer_4_combine_shakti_051702052025'\n",
    "config = GPT2Config.from_pretrained(save_dir)\n",
    "model_charged = CondGPT2.from_pretrained(save_dir, config=config)\n",
    "# model_charged.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_charged.eval()\n",
    "\n",
    "fast_tokenizer = PreTrainedTokenizerFast.from_pretrained('/home/lamedinaa/testing_rl/data/5_models_LP/models/model_condtransformer_4_nihal_351905032025')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2bbb2edd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "t = torch.tensor([1,2], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "753edc0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_charged\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel_charged\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 1) Prompt y tokenizaciÃ³n inicial\u001b[39;00m\n\u001b[1;32m      6\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[BOS]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/testing_rl/env/lib/python3.10/site-packages/transformers/modeling_utils.py:3698\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   3694\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3695\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3696\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3697\u001b[0m         )\n\u001b[0;32m-> 3698\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/testing_rl/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/testing_rl/env/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/testing_rl/env/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/testing_rl/env/lib/python3.10/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/testing_rl/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "model_charged.eval()\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_charged.to(device)\n",
    "\n",
    "# 1) Prompt y tokenizaciÃ³n inicial\n",
    "prompt = \"[BOS]\"\n",
    "inputs = fast_tokenizer(prompt, return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"].to(model_charged.device)\n",
    "attention_mask = inputs[\"attention_mask\"].to(model_charged.device)\n",
    "\n",
    "# 2) Tensor de condiciÃ³n (batch_size=1)\n",
    "reward_tensor     = torch.tensor([190/200], device=model_charged.device)  # normalizado\n",
    "prob_fault_tensor = torch.tensor([0], device=model_charged.device)\n",
    "\n",
    "# reward_tensor = torch.tensor([190/200]) \n",
    "# prob_fault_tensor = torch.tensor([0.8])\n",
    "\n",
    "# 3) GeneraciÃ³n\n",
    "outputs = model_charged.generate(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    reward=reward_tensor,        # aquÃ­ pasas tu condiciÃ³n\n",
    "    prob_fault=prob_fault_tensor,\n",
    "    max_length=300,\n",
    "    do_sample=True,\n",
    "    temperature=1.0,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=20,\n",
    ")\n",
    "\n",
    "# 4) Decodificar\n",
    "for i, out in enumerate(outputs):\n",
    "    text = fast_tokenizer.decode(out, skip_special_tokens=True)\n",
    "    print(f\"GeneraciÃ³n {i+1}:\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b737cb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneraciÃ³n 1: w20 1 w20 0 w20 1 w28 0 w28 1 w28 0 w12 0 w12 1 w12 0 w17 1 w5 0 w12 1 w18 0 w18 1 w18 0 w18 1 w17 0 w17 0 w17 1 w17 0 w1 1 w17 0 w1 1 w1 0 w1 1 w1 0 w31 1 w31 0 w31 0 w31 1 w4 0 w4 1 w4 0 w4 1 w4 0 w2 1 w2 0 w2 0 w2 1 w14 0 w14 1 w14 0 w14 1 w8 0 w8 1 w8 0 w8 1 w22 0 w22 0 w22 1 w22 0 w22 1 w26 0 w26 0 w26 0 w26 1 w15 0 w15 1 w15 0 w15 0 w25 1 w25 0 w25 1 w25 0 w19 1 w19 0 w19 0 w19 1 w5 0 w5 1 w5 1 w5 0 w5 0 w11 1 w11 0 w11 0 w11 1 w11 1 w13 0 w13 0 w13 1 w10 0 w10 1 w10 0 w10 1 w10 0 w9 0 w9 1 w9 0 w9 1 w27 0 w27 1 w27 0 w27 1 w16 0 w16 0 w16 1 w16 0 w3 1 w3 0 w3 1 w3 0 w6 1 w6 0 w6 1 w6 0 w7 0 1 w7 0 True\n",
      "GeneraciÃ³n 2: w32 1 w20 0 w20 1 w20 0 w28 1 w28 0 w28 1 w28 0 w12 0 w12 1 w12 0 w12 1 w18 0 w18 1 w18 0 w18 1 w18 0 w17 0 w17 1 w17 0 w17 1 w17 0 w1 1 w1 0 w1 1 w1 0 w1 1 w31 1 w31 0 w31 0 w31 1 w4 1 w4 0 w4 1 w4 0 w4 1 w2 0 w2 1 w2 0 w2 1 w2 0 w14 0 w14 1 w14 0 w14 1 w8 0 w8 1 w8 0 w8 1 w22 0 w22 1 w22 0 w22 0 w22 1 w26 0 w26 1 w26 0 w26 1 w15 0 w15 0 w15 1 w15 0 w25 1 w25 0 w25 1 w25 0 w19 1 w19 0 w19 0 w19 1 w5 0 w5 0 w5 1 w5 0 w5 1 w11 0 w11 1 w11 0 w11 0 w13 1 w13 0 w13 1 w10 0 w10 1 w10 0 w10 0 w10 1 w9 0 w9 1 w9 0 w9 0 w27 1 w27 0 w27 1 w27 0 w27 1 w16 0 w16 0 w16 1 w3 0 w3 1 w3 0 1 w3 0 w6 1 w6 0 w6 0 w6 1 w7 0 w7 1 w7 0 w7 1 True\n",
      "GeneraciÃ³n 3: w20 1 w20 0 w20 1 w28 0 w28 1 w28 0 w12 0 w12 1 w12 0 w12 1 w12 0 1 w18 0 1 w18 0 0 w17 0 w17 1 0 w17 1 w17 0 w17 1 w1 0 w1 1 w1 0 w1 1 w1 0 w31 1 w31 0 w31 1 w31 0 w31 0 w4 1 w4 0 w4 1 w4 0 w4 1 w2 0 w2 1 w2 0 w2 1 w14 0 w14 1 w14 0 w14 0 w8 1 w8 1 w8 0 w8 0 w22 1 w22 0 w22 0 w22 1 w22 0 w26 1 w26 0 w26 1 w15 0 w15 0 w15 1 w15 1 w15 0 w25 0 w25 1 w25 0 w25 1 w19 0 w19 0 w19 1 w19 0 w5 1 w5 1 w5 0 w5 1 w5 0 w11 0 w11 1 w11 0 w11 1 w13 0 w13 1 w13 0 w13 1 w10 0 w10 1 w10 0 w10 0 w9 1 w9 0 w9 1 w9 0 w27 0 w27 1 w27 0 w27 1 w27 0 w16 1 w16 0 w16 1 w16 0 w3 0 w3 1 w3 0 w6 1 w6 0 w6 1 w6 0 w7 0 w7 1 w7 0 True\n",
      "GeneraciÃ³n 4: w20 1 w20 1 w28 0 w12 1 w15 0 w22 1 w28 0 1 w28 0 w28 1 w14 0 w12 1 w12 0 w12 1 w18 0 w39 1 w18 0 1 w18 0 w18 1 w17 0 w17 0 w17 1 w17 0 w17 1 w19 0 w1 1 w1 0 w1 1 w1 0 w31 0 w31 1 w31 1 w31 0 w4 0 w4 1 w4 0 w4 1 w4 0 w2 1 w2 0 w2 1 w2 0 w2 0 w14 1 w14 0 w14 1 w14 0 w8 1 w8 0 w8 1 w8 0 w22 1 w22 0 w22 0 w22 1 w22 0 w26 0 w26 1 w26 1 w26 0 w15 0 w15 1 w15 0 w15 1 w15 0 w25 1 w25 0 0 w19 1 w19 0 w19 1 w19 0 w5 0 w5 1 w5 1 w5 0 w11 0 w11 1 w11 0 w11 0 w13 1 w13 0 w13 1 w13 1 w10 0 w10 1 w10 0 w10 0 w9 1 w9 0 w9 1 w27 0 w27 0 w27 1 w27 1 w27 0 w16 0 w16 1 w16 0 1 w3 0 w3 1 w3 0 w3 0 w6 1 w6 1 w6 0 w6 0 w7 1 w7 0 w7 1 w13 0 True\n",
      "GeneraciÃ³n 5: w32 1 w20 1 w20 0 w20 0 w28 1 w28 0 w28 1 w28 0 w12 0 w12 1 w12 0 w12 1 w18 0 w18 1 w18 0 w18 1 w17 0 w17 1 w17 0 w17 0 w17 1 w1 0 w1 1 w1 0 w1 1 w1 0 w31 1 w31 0 w31 1 w31 0 w4 0 w4 1 w4 0 w4 1 w4 0 w4 1 w2 0 w2 1 w2 0 w2 1 w14 0 w14 1 w14 0 w14 0 w8 1 w8 0 w8 1 w8 0 w22 0 w22 1 w22 0 w22 1 w22 0 w26 1 w26 0 w26 1 w26 0 w15 0 w15 1 w15 0 w15 1 w25 0 w25 1 w25 0 w25 1 w19 0 w19 0 w19 1 w19 0 w19 1 w5 1 w5 0 w5 0 w5 1 w11 1 w11 0 w11 0 w11 1 w13 0 w13 1 w13 0 w13 1 w10 0 w10 0 w10 1 w10 0 w9 1 w9 0 w9 1 w9 0 w27 0 w27 1 w27 0 w27 1 w27 0 w16 0 w16 1 w16 0 w3 1 w3 0 w3 1 w3 0 w6 1 w6 0 w6 1 w6 0 w7 0 w7 1 w7 0 w15 1 w7 0 True\n",
      "GeneraciÃ³n 6: w20 1 w20 0 w28 1 w28 0 w12 1 w15 0 w28 1 w12 0 w12 0 w12 1 w40 0 w12 1 w18 0 w18 1 w18 0 w18 0 w17 1 w17 0 w17 1 w17 0 w17 1 w1 0 w1 1 w1 0 w1 1 w1 0 w31 1 w31 0 w31 0 w31 1 w4 0 w4 1 w4 0 w4 1 w4 0 w4 1 w2 0 w2 1 w2 0 w2 1 w14 0 w14 1 w14 0 w14 1 w8 0 w8 0 w8 1 w8 0 w22 1 w22 0 w22 0 w22 1 w22 0 w26 1 w26 0 w26 1 w26 0 w15 1 w15 0 w15 1 w15 0 w15 0 w25 1 w25 0 w25 1 w19 0 w19 1 w19 0 w19 0 w19 1 w5 0 w5 1 w5 0 w5 0 w11 1 w11 0 w11 1 w11 0 w13 1 w13 0 w13 0 w13 1 w10 0 w10 0 w10 1 w10 0 w9 1 w9 0 w9 0 w9 1 w27 0 w27 1 w27 0 w27 1 w16 0 w16 0 w16 1 w16 0 1 w3 0 w3 1 w3 0 w6 1 w6 0 w6 1 w6 0 0 w7 1 w7 0 w7 1 True\n",
      "GeneraciÃ³n 7: w32 1 w20 0 w28 1 w20 0 w28 1 w28 0 w28 0 w12 1 w12 0 w12 1 0 w12 0 w18 1 w18 0 w18 0 w18 1 w17 0 w17 1 w17 0 w17 1 w1 0 w1 1 w1 0 w1 0 w31 1 w31 1 w31 0 w31 1 w4 0 w4 0 w4 1 1 w4 0 w4 1 w2 0 w2 1 w2 0 w2 0 w14 1 w14 0 w14 1 w14 0 w8 1 w8 0 w8 0 w8 1 w22 0 w22 0 w22 1 w22 0 w22 1 w26 0 w26 1 w26 0 w15 1 w15 0 w15 0 w15 1 w15 0 w25 1 w25 0 w25 1 w25 0 w19 0 w19 1 w19 0 w19 1 w5 0 w5 1 w5 0 w5 1 w11 0 w11 0 w11 1 w11 0 w11 0 w13 1 w13 0 w13 1 w10 0 w10 1 w10 0 w10 1 w10 0 w9 0 w9 1 w9 0 w9 0 w27 1 w27 0 w27 1 w27 0 w27 1 w16 0 w16 1 w16 0 0 1 w3 0 w3 1 w3 0 w6 1 w6 0 w6 1 w6 0 w7 0 w7 1 w7 0 True\n",
      "GeneraciÃ³n 8: w20 1 0 w20 1 0 w20 1 w28 0 w28 0 w28 1 w28 0 w12 1 w12 0 w12 0 w12 1 w12 0 w18 1 w18 0 w18 1 w18 0 w17 0 w17 1 w17 0 w17 1 w17 0 w1 1 w1 0 w1 1 w1 0 w1 1 w31 0 w31 1 w31 0 w31 0 w4 1 w4 1 w4 0 w4 0 w4 1 w2 0 w2 1 w2 0 w2 1 w2 0 w14 1 w14 0 w14 0 w14 1 w8 0 w8 1 w8 0 w8 0 w22 1 w22 0 w22 1 w22 0 w22 0 w22 1 w26 0 w26 0 w26 1 w15 1 w15 0 w15 1 w15 0 w25 0 w25 1 w25 0 w25 1 w19 0 w19 1 w19 0 w19 1 w19 0 w5 1 w5 0 w5 0 w5 1 w5 0 w11 1 w11 0 w11 1 w11 0 w13 0 w13 1 w13 0 w13 1 w10 0 w10 0 w10 1 w10 0 w9 1 w9 0 w9 0 w9 1 w27 0 w27 1 w27 0 w27 1 w16 0 w16 0 w16 1 w16 0 w3 1 w3 0 w3 1 w3 0 w6 1 w6 0 w6 0 w6 1 w7 0 w7 1 w7 0 w7 1 True\n",
      "GeneraciÃ³n 9: w20 1 0 1 w20 0 w20 0 w28 1 w28 0 w28 1 w28 0 w12 1 w12 0 w12 0 w12 1 w18 0 w18 1 w18 0 w18 1 w18 0 w17 0 w17 1 w17 0 w17 1 w17 0 w1 1 w1 0 w1 1 w1 0 w1 1 w31 0 w31 1 w31 0 w31 0 w4 1 w4 0 w4 1 w4 0 w4 1 w4 0 w2 1 w2 0 w2 1 w2 0 w14 1 w14 0 w14 0 w14 1 w8 0 w8 1 w8 0 w8 1 w22 0 w22 1 w22 0 w22 0 w22 1 w26 0 w26 1 w26 0 w26 0 w15 1 w15 0 w15 1 w15 0 w15 1 w25 0 w25 0 w25 1 w19 0 w19 1 w19 0 w19 1 w5 0 w5 1 w5 0 w5 0 w5 1 w11 0 w11 1 w11 0 w11 1 w13 0 w13 0 w13 1 w13 0 w10 1 w10 0 w10 0 w10 1 w9 0 w9 1 w9 0 w9 1 w9 0 w27 0 w27 1 w27 0 w27 1 w16 0 w16 1 w16 1 w3 0 w3 1 w3 0 w3 1 w3 0 w6 1 w6 0 w6 0 w6 1 w7 0 w7 1 w7 0 w7 1 True\n",
      "GeneraciÃ³n 10: w20 1 w20 1 w20 0 w28 0 w28 1 w28 0 w12 1 w12 0 w12 0 w12 1 w18 0 w18 1 w18 0 w18 1 w17 0 w19 0 w17 1 w17 0 w17 1 w17 0 w1 1 w1 0 w1 1 w1 0 w1 1 w31 0 w31 1 w31 0 w31 0 w4 1 w4 0 w4 1 w4 0 w4 1 w2 0 w2 1 w2 0 w2 1 w14 0 w14 1 w14 0 w14 0 w8 1 w8 0 w8 1 w8 0 w22 1 w22 0 w22 0 w22 1 w22 0 w22 1 w26 0 w26 1 w26 0 w26 1 w15 0 w15 0 w15 1 w15 0 w25 1 w25 0 w25 0 w25 1 w19 0 w19 1 w19 0 w19 1 w5 0 w5 1 w5 0 w5 0 w5 1 w11 0 w11 1 w11 0 w11 1 w13 0 w13 0 w13 1 w13 0 w10 1 w10 0 w10 0 w10 1 w9 0 w9 1 w9 0 w9 0 w27 1 w27 0 w27 1 w27 0 w27 1 w16 0 w16 1 w16 0 w3 0 w3 1 w3 0 w3 1 w3 0 w6 1 w6 0 w6 1 w6 0 w7 0 w7 1 w7 0 True\n",
      "GeneraciÃ³n 11: w20 1 w20 0 w28 1 w28 0 w28 1 w28 0 w12 0 w12 1 w12 0 w12 1 w26 0 w18 1 0 0 w18 1 w18 0 0 w17 1 w17 0 w17 1 1 0 w17 0 w1 1 w1 0 w1 1 w31 0 w31 1 w31 0 w31 1 w4 0 w4 0 0 w4 1 w4 0 w4 1 w4 0 w2 1 w2 0 w2 1 w14 0 w14 1 w14 0 w14 1 w8 1 w8 0 w8 1 w8 0 w22 0 w22 1 w22 0 w22 0 w22 1 w26 1 w26 0 w26 1 w26 0 w15 1 w15 0 w15 1 w15 0 w25 1 w25 0 w25 0 w19 1 w19 0 w19 0 w19 1 w5 0 w5 0 w5 1 w5 0 w5 1 w11 0 w11 1 w11 0 w11 0 w13 1 w13 0 w13 1 w13 0 w10 1 w10 0 w10 0 w10 1 w10 0 w9 1 w9 0 w9 1 w9 0 w27 0 w27 1 w27 0 w27 1 w16 0 w16 1 w16 0 w16 0 w3 1 w3 0 w3 1 w3 0 w6 1 w6 0 w6 1 w6 0 w7 1 w7 0 w7 0 w7 1 True\n",
      "GeneraciÃ³n 12: w20 1 w20 0 w28 1 w15 0 w28 1 0 w26 0 w12 1 w28 0 w12 1 w28 0 w12 1 w12 0 w18 1 w18 0 w18 1 w18 0 w18 0 w17 1 w17 0 w17 1 w17 0 w17 1 w1 0 w1 1 w1 0 w1 1 w1 0 w31 0 w31 1 w31 0 w31 1 w4 0 w4 1 w4 0 w4 1 w4 0 w2 1 w2 0 w2 1 w2 0 w14 1 w14 0 w14 0 w14 1 w14 0 w8 1 w8 0 w8 1 w8 0 w22 1 w22 0 w22 0 w22 1 w22 0 w26 1 w26 0 w26 1 w26 0 w15 1 w15 0 w15 0 w15 1 w15 0 w25 1 w25 0 w25 1 w25 0 w19 0 w19 1 w19 0 w19 1 w5 0 w5 0 w5 1 w5 0 w5 1 w11 0 w11 1 w11 0 w13 0 w13 1 w13 0 w13 1 w13 0 w10 1 w10 0 w10 0 w10 1 w9 0 w9 1 w9 0 1 w27 0 w27 1 w27 0 w27 1 w16 0 w16 1 w16 0 w16 1 w3 0 1 w3 0 w3 0 w6 1 w6 1 w6 0 w7 0 w7 1 w7 0 w7 1 True\n",
      "GeneraciÃ³n 13: w20 1 w20 0 w28 1 w20 0 w28 1 w28 0 w12 0 1 w12 0 True 1 w26 0 1 0 w17 0 1 1 1 0 0 True 0 0 w40 1 0 w18 1 w10 0 0 w5 1 w14 1 w17 0 0 w17 1 w17 0 w17 1 0 w1 1 w1 0 w1 1 w1 0 w31 0 w31 1 w31 0 w31 1 w4 0 w4 1 w4 0 w4 1 w2 0 w2 1 w2 0 w2 1 w14 0 w14 1 w14 0 w14 0 w8 1 w8 0 w8 1 w8 0 w22 1 w22 0 w22 1 w22 0 w22 0 w26 1 w26 0 w26 1 w15 0 w15 0 w15 1 w15 0 w25 1 w25 0 w25 0 w25 1 w19 0 w19 1 w19 0 w19 1 w5 0 w5 1 w5 0 w5 0 w5 1 w11 0 w11 0 w11 1 w13 0 w13 1 w13 0 w13 1 w10 0 w10 0 w10 1 w10 0 1 w9 0 w9 1 w9 0 w27 0 w27 1 w27 0 w27 1 w27 0 w16 1 w16 1 w16 0 w3 0 w3 0 w3 1 w3 0 w6 1 w6 1 w6 1 w6 0 w7 0 w7 1 w7 0 True\n",
      "GeneraciÃ³n 14: w20 1 w28 1 w20 0 w20 1 w28 0 w28 0 w28 1 w12 0 w12 0 w12 1 w12 0 w12 1 w18 0 w18 1 w18 0 w18 1 w17 0 w17 1 w17 0 w17 0 w17 1 w1 0 w1 1 w1 0 w1 1 w1 0 w31 1 w31 0 w31 1 w31 1 w4 0 w4 0 w4 0 w4 1 w4 0 1 w2 0 w2 1 w2 0 w14 1 w14 0 w14 1 w14 0 w14 0 w8 1 w8 0 w8 1 w8 0 w22 0 w22 1 w22 1 w22 0 w22 0 w26 1 w26 0 w26 1 w26 0 w15 0 w15 1 w15 0 w15 1 w25 0 w25 1 w25 0 w25 1 w19 0 w19 0 w19 1 w19 0 w19 1 w5 0 w5 0 w5 1 w5 0 w11 1 w11 0 w11 1 w11 0 w13 0 w13 1 w13 0 w13 1 w10 0 w10 0 w10 1 w10 0 w9 1 w9 0 w9 0 w9 1 w9 0 w27 1 w27 0 w27 1 w27 0 w16 1 w16 0 w16 1 w16 1 w3 0 w3 1 w3 0 w3 0 w3 1 w6 0 w6 1 w6 0 w7 1 w7 0 w7 1 w7 0 True\n",
      "GeneraciÃ³n 15: w32 1 w20 1 w20 0 w20 0 w28 1 w28 0 w28 1 w28 0 w12 1 w12 0 w12 0 w12 1 w18 0 w18 1 w18 0 w18 1 w17 0 w17 1 w17 0 w17 1 w17 0 w1 0 w1 1 w1 0 w1 1 w1 0 w31 1 w31 0 w31 1 w31 0 w4 1 w4 0 w4 1 w4 0 w4 1 w4 0 w2 1 w2 0 w2 1 w2 1 w14 0 w14 1 w14 0 w14 0 w8 1 w8 0 w8 1 w8 0 w22 0 w22 1 w22 0 w22 1 w22 0 w26 1 w26 0 w26 0 w15 1 w15 0 w15 1 w15 0 w15 1 w25 0 w25 1 w25 0 w25 0 w19 1 w19 0 w19 1 w19 0 w19 1 w5 0 w5 0 w5 1 w5 0 w11 1 w11 0 w11 1 w11 0 w13 0 w13 1 w13 0 w13 1 w10 0 w10 0 w10 1 w10 0 w9 1 w9 0 w9 1 w9 0 w9 0 w27 1 w27 0 w27 1 w27 0 w16 0 w16 1 w16 0 w3 1 w3 0 w3 1 w3 0 1 w3 0 w6 1 w6 0 w6 1 w6 0 w7 0 1 w7 0 True\n",
      "GeneraciÃ³n 16: w20 1 w28 0 w12 1 w20 0 1 w20 0 w20 0 w28 1 w28 0 w28 1 w28 0 w28 1 w12 0 w12 1 w12 0 w12 1 w18 0 w18 0 w18 1 w18 0 w17 1 w17 0 w17 1 w17 0 w17 1 w1 0 w1 1 w1 0 w1 0 w1 1 w31 0 w31 1 w31 0 w31 1 w4 0 w4 1 w4 0 w4 1 w4 0 w2 1 w2 0 w2 1 w2 0 w2 1 w14 0 w14 0 w14 1 w14 0 w8 1 w8 0 w8 1 w8 0 w22 0 w22 1 w22 0 w22 1 w22 0 w26 1 w26 0 w26 1 w26 0 w15 0 w15 1 w15 0 w15 1 w25 0 w25 1 w25 0 w19 0 w19 1 w19 0 w19 1 w19 0 w5 0 w5 1 w5 0 w5 1 w5 0 w11 0 w11 1 w11 1 w11 0 w13 0 w13 1 w13 0 w13 0 w10 1 w10 0 w10 1 w10 0 w9 1 w9 0 w9 0 w9 1 w27 0 w27 1 w27 0 w27 1 w16 0 w16 0 w16 1 w16 0 w3 1 w3 0 w3 1 w3 0 w6 1 w6 0 w6 1 w6 0 w7 0 w7 1 w7 0 w7 1 True\n",
      "GeneraciÃ³n 17: w20 1 w12 0 w17 1 w32 0 w20 1 w20 0 w20 0 w28 1 w28 0 w28 1 w28 0 w28 1 w12 0 w12 1 w12 0 w12 0 w12 1 w18 0 w18 1 w18 0 w18 1 w17 0 w17 1 w17 0 w17 1 w17 0 w1 0 w1 1 w1 0 w1 1 w1 0 w31 1 w31 0 w31 1 w31 0 w4 1 w4 0 w4 1 w4 0 w4 1 w2 0 w2 1 w2 0 w2 1 w14 0 w14 1 w14 0 w14 0 w8 1 w8 0 w8 1 w8 0 w22 1 w22 0 w22 0 w22 1 w22 0 w26 1 w26 0 w26 0 w15 1 w15 0 w15 1 w15 0 w15 1 w25 0 w25 1 w25 0 w19 0 w19 1 w19 0 w19 1 w5 0 w5 0 w5 1 w5 0 w11 1 w11 0 w11 1 w11 0 w13 0 w13 1 w13 0 w13 1 w10 0 w10 0 w10 1 w10 0 w10 1 w9 0 w9 0 w9 1 w9 1 w27 0 w27 0 w27 1 w27 0 w16 1 w16 0 w16 0 w16 1 w3 0 w3 1 w3 0 1 w6 0 w6 1 w6 0 w7 1 w7 0 w7 0 w15 1 w7 0 True\n",
      "GeneraciÃ³n 18: w20 1 w28 0 w20 1 w20 0 w28 1 w28 0 w28 0 w12 1 w12 0 w12 1 0 w14 1 w15 0 0 w18 1 w15 0 0 w18 1 w18 1 w17 0 w4 0 w17 1 w17 0 w17 1 1 0 w17 1 0 0 w1 1 w1 0 w1 1 w1 1 w31 0 w31 0 w31 0 w31 1 w4 0 w4 1 w4 0 w4 1 w4 0 w2 1 w2 0 w2 1 w2 0 w2 1 w14 0 w14 0 w14 1 w14 0 w8 1 w8 0 w8 1 w8 0 w22 1 w22 0 w22 0 w22 1 w22 0 w26 1 w26 0 w26 0 w15 1 w15 0 w15 1 w15 0 w15 1 w25 0 w25 1 w25 0 w19 0 w19 1 w19 0 w19 1 w5 0 w5 1 w5 0 w5 0 w5 1 w11 0 w11 1 w11 0 w11 0 w13 1 w13 0 w13 1 w10 0 w10 0 w10 1 w10 0 w9 1 w9 0 w9 0 w9 1 w27 0 w27 1 w27 0 w27 1 w27 0 w16 1 w16 0 w16 1 w3 1 w3 0 0 w3 1 0 w6 1 w6 0 w6 1 w7 0 w7 1 w7 0 w7 0 w7 0 True\n",
      "GeneraciÃ³n 19: w20 1 w28 0 w15 1 w20 0 w20 1 w28 0 w28 1 w28 0 w28 0 w12 1 w12 0 w12 1 w12 0 w18 1 w18 0 w18 1 w18 0 w18 0 w17 1 w17 0 w17 1 w17 0 w17 1 1 w1 0 w1 1 w1 0 w31 0 w31 1 w31 1 w31 0 w4 1 w4 0 w4 0 w4 1 1 w4 1 w4 0 w2 1 w2 0 w2 0 w14 0 w14 1 w14 0 w14 1 w14 0 w8 0 w8 1 w8 0 w8 1 w22 0 w22 1 w22 0 w22 0 w22 1 w26 0 w26 1 w26 0 w26 1 w15 0 w15 0 w15 1 w15 0 w25 1 w25 0 w25 1 w25 0 w19 1 w19 0 w19 0 w19 1 w5 0 w5 0 w5 1 w5 0 w5 1 w11 0 w11 1 w11 0 w11 1 w13 0 w13 0 w13 1 w13 0 w10 0 w10 1 w10 1 w10 0 w9 0 w9 1 w9 0 w9 0 w9 1 w27 0 w27 1 w27 0 w16 0 w16 1 w16 0 w16 1 w3 0 w3 1 w3 0 w3 1 w3 0 w6 1 w6 0 w6 1 w6 0 w7 0 w7 1 w7 0 True\n",
      "GeneraciÃ³n 20: w20 1 0 w20 0 1 w20 0 w28 1 w28 0 w28 1 w28 0 w12 0 w12 1 w12 0 w12 1 w18 0 w18 1 w18 0 w18 1 w17 0 w17 0 w17 1 w17 0 w17 1 w1 0 w1 1 w1 0 w1 1 w1 0 w31 1 w31 0 w31 1 w31 0 w31 0 w4 1 w4 0 w4 1 w4 0 w4 1 w2 0 w2 1 w2 0 w2 1 w14 0 w14 1 w14 0 w14 0 w8 1 w8 0 w8 1 w8 0 w22 1 w22 0 w22 0 w22 1 w22 0 w26 1 w26 0 w26 1 w26 0 w15 0 w15 1 w15 0 w15 1 w15 0 w25 1 w25 0 w25 1 w25 0 w19 0 w19 1 w19 0 w19 1 w5 1 w5 0 w5 0 w5 1 w5 0 w11 1 w11 0 w11 0 w11 1 w13 0 w13 1 w13 0 w13 0 w10 1 w10 1 w10 0 w10 1 w10 0 w9 0 w9 1 w9 0 w27 1 w27 0 w27 0 w27 1 w16 0 w16 1 w16 0 w16 1 w3 0 w3 1 w3 0 w3 0 w6 1 w6 0 w6 1 w6 0 w7 1 w7 0 w7 1 w7 0 True\n"
     ]
    }
   ],
   "source": [
    "model_charged.eval()\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_charged.to(device)\n",
    "\n",
    "# 1) Prompt y tokenizaciÃ³n inicial\n",
    "prompt = \"[BOS]\"\n",
    "inputs = fast_tokenizer(prompt, return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"].to(model_charged.device)\n",
    "attention_mask = inputs[\"attention_mask\"].to(model_charged.device)\n",
    "\n",
    "# 2) Tensor de condiciÃ³n (batch_size=1)\n",
    "reward_tensor     = torch.tensor([90/200], device=model_charged.device)  # normalizado\n",
    "prob_fault_tensor = torch.tensor([1], device=model_charged.device)\n",
    "\n",
    "# reward_tensor = torch.tensor([190/200]) \n",
    "# prob_fault_tensor = torch.tensor([0.8])\n",
    "\n",
    "# 3) GeneraciÃ³n\n",
    "outputs = model_charged.generate(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    reward=reward_tensor,        # aquÃ­ pasas tu condiciÃ³n\n",
    "    prob_fault=prob_fault_tensor,\n",
    "    max_length=300,\n",
    "    do_sample=True,\n",
    "    temperature=1.0,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=20,\n",
    ")\n",
    "\n",
    "# 4) Decodificar\n",
    "for i, out in enumerate(outputs):\n",
    "    text = fast_tokenizer.decode(out, skip_special_tokens=True)\n",
    "    print(f\"GeneraciÃ³n {i+1}:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09b40a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneraciÃ³n 1: w37 1 w39 1 w11 1 w36 0 w37 1 w36 1 w36 0 w36 0 w37 1 w37 0 w36 1 w35 0 w35 0 w36 1 w35 0 w40 1 w35 0 w35 1 w35 0 w39 1 w33 0 w35 0 w33 1 w33 1 w33 0 w33 1 w33 0 w34 1 w34 0 w34 1 w29 0 w34 1 w34 0 w29 1 w29 0 w29 1 w29 1 w29 0 w29 0 w21 1 w29 1 w21 1 w21 0 w21 1 w21 0 w21 1 w21 1 w24 1 w24 1 w24 0 w24 0 w24 0 w24 1 w30 1 w24 0 w30 0 w30 1 w30 1 w30 0 w30 1 True 0 w23 0 w23 0 w23 1 w23 0 w32 1 w32 0 w32 1 w32 0 w20 0 w20 1 w20 0 w20 1 w20 0 w28 1 w28 0 w28 0 w28 1 w12 1 w28 1 w12 0 w12 0 w18 0 w18 0 w18 1 w18 1 w18 0 w17 1 w17 0 w17 1 w17 0 w1 1 w1 0 w1 1 w1 1 w31 0 w31 1 w4 0 w31 0 w4 1 w4 1 w4 0 w4 0 w4 0 w4 1 w2 0 w2 1 w2 0 w2 1 w14 1 w14 0 w14 1 w14 0 w14 1 w14 0 w8 1 w8 0 w8 0 w8 0 w8 1 w8 0 w22 1 w22 0 w26 1 w26 0 w26 1 w15 0 w15 1 w15 0 w15 0 w15 1 w15 0 w25 1 w25 0 w25 1 w25 0 w19 1 w19 0 w19 1 w5 0 w5 0 w5 0 w5 1 w5 0 w11 1 w5 0 w11 0 w11 1 w11 0 w13\n",
      "GeneraciÃ³n 2: w36 1 w35 1 w37 1 w40 1 w39 0 w37 1 w37 0 w39 1 w37 0 w37 0 w36 1 w37 0 w38 1 w40 0 w36 1 w36 0 w36 1 w36 0 w36 1 w36 0 w35 0 w33 1 w35 0 w33 1 w35 0 w35 1 w33 0 w33 1 w33 0 w34 1 w34 0 w34 1 w34 0 w34 1 w34 0 w34 1 w29 0 w29 1 w29 1 w29 0 w29 0 w29 1 w21 1 w29 1 w21 0 w21 1 w21 0 w21 1 w24 1 w21 0 w32 0 w24 1 w24 0 w24 0 w24 1 w30 1 w30 0 w30 1 w12 1 w17 1 w32 0 w26 0 w12 1 w15 1 w39 0 w17 0 w23 1 w19 0 w4 1 w2 0 w32 0 w14 1 w26 0 w17 0 w26 1 w22 1 w26 0 w25 1 w25 0 w19 1 w19 0 w19 0 w19 1 w5 0 w5 1 w11 0 w11 0 w11 1 w13 0 w13 1 w10 0 w10 1 w10 1 w10 0 w9 0 w9 0 w27 1 w27 0 w27 0 w27 1 w16 0 w16 1 w16 0 w16 1 w16 1 w3 0 w3 1 w3 0 w3 1 w3 0 w6 1 w6 0 w7 1 w7 0 w7 1 True\n",
      "GeneraciÃ³n 3: w39 1 w36 w37 w36 1 w37 0 w36 0 w39 1 w35 0 w36 1 w37 0 w39 0 w37 1 w36 0 w37 1 w37 0 w36 1 w37 0 w37 1 w37 1 w36 0 w36 1 w35 0 w33 1 w36 0 w35 1 w35 0 w35 1 w33 1 w33 1 w33 0 w33 1 w34 0 w33 1 w34 0 w34 1 w32 0 w34 1 w29 1 w29 1 w29 0 w34 0 w29 0 w32 1 w29 1 w20 1 w28 1 w12 0 w18 1 w18 0 w17 0 w17 1 w1 0 w31 1 w31 0 w31 1 w4 0 w4 1 w2 0 w2 1 w2 0 w2 0 w14 1 w14 0 w8 0 w8 1 w8 0 w22 1 w22 0 w22 1 w26 0 w26 1 w15 0 w15 0 w15 1 w15 0 w25 1 w25 0 w25 0 w19 1 w19 0 w19 0 w19 1 w5 1 w5 0 w5 1 w11 0 w11 1 w11 0 w13 1 w13 0 w13 0 w10 1 w10 0 w10 1 w10 0 w9 0 w9 0 w9 0 w27 1 w27 0 w27 1 w27 0 w16 1 w16 1 w16 0 w16 1 w16 0 w16 1 w3 0 w3 1 w3 1 w3 0 w3 0 w6 1 w6 0 w6 1 w6 0 w7 0 w7 1 w7 1 True\n",
      "GeneraciÃ³n 4: w35 1 w37 1 w35 1 w37 0 w36 0 w37 0 w17 1 w37 0 w39 0 w37 0 w36 1 w39 0 w39 1 w39 0 w37 1 w37 0 w39 0 w36 1 w37 0 w36 1 w36 0 w39 1 w7 0 w36 1 w39 0 w36 1 w24 0 w36 1 w36 0 w30 1 w23 0 w36 1 w32 0 w20 1 w28 0 w28 1 w12 1 w12 0 w18 0 w18 1 w18 0 w17 1 w17 0 w1 1 w1 0 w31 1 w31 0 w31 1 w4 0 w4 1 w4 0 w4 1 w2 0 w2 1 w2 0 w2 1 w14 0 w14 1 w14 0 w8 1 w8 0 w22 0 w22 0 w22 1 w22 0 w26 1 w26 0 w26 1 w15 0 w15 0 w15 1 w15 0 w25 1 w25 0 w25 1 w25 0 w19 1 w19 0 w19 0 w19 1 w5 0 w5 1 w5 0 w11 0 w11 1 w11 0 w11 0 w13 1 w13 0 w13 0 w10 1 w10 0 w10 1 w10 0 w9 0 w9 1 w9 0 w9 1 w27 0 w27 0 w27 1 w27 0 w27 0 w16 1 w16 1 w16 0 w16 1 w16 0 w3 1 w3 0 w3 1 w3 1 w3 1 w6 0 w6 0 w6 1 w7 1 w7 1 w7 0 w7 1 True\n",
      "GeneraciÃ³n 5: w40 1 w36 1 w36 1 w35 0 w22 0 w37 1 w39 0 w39 1 w37 0 w37 0 w38 1 w37 0 w36 1 w37 0 w33 1 w37 0 w37 0 w35 1 w37 0 w35 1 w35 0 w33 1 w33 0 w35 1 w33 0 w34 1 w34 0 w34 1 w34 0 w34 1 w29 0 w34 1 w29 0 w29 1 w21 0 w21 1 w21 0 w21 1 w24 0 w24 1 w24 1 w24 0 w24 0 w30 1 w30 1 w23 1 w30 0 w23 0 w23 1 w32 0 w32 1 w20 0 w20 1 w28 0 w20 1 w28 0 w12 1 w18 0 w18 1 w18 0 w17 0 w17 1 w1 0 w1 1 w31 0 w31 1 w4 0 w4 0 w4 1 w2 1 w2 0 w2 0 w14 1 w14 0 w14 0 w8 1 w8 0 w8 0 w22 1 w22 0 w22 1 w26 0 w26 1 w26 0 w26 1 w15 0 w15 0 w25 1 w25 0 w25 0 w25 1 w19 0 w19 1 w19 0 w19 1 w5 0 w5 1 w5 0 w11 0 w11 1 w13 0 w13 1 w13 0 w13 1 w10 0 w10 0 w10 1 w9 0 w9 1 w9 0 w9 0 w27 0 w27 1 w27 0 w27 1 w16 0 w16 1 w16 0 w16 1 w3 0 w3 1 w3 0 w3 1 w3 0 w6 0 w6 1 w6 0 w6 0 w7 1 w7 1 w7 0 True\n",
      "GeneraciÃ³n 6: w39 0 w37 1 w37 1 w37 0 w35 1 w37 0 w37 0 w39 1 w36 0 w39 0 w36 1 w36 0 w36 1 w36 0 w36 1 w36 0 w37 1 w35 0 w35 0 w35 1 w36 1 w35 1 w35 0 w33 1 w35 0 w35 1 w33 0 w34 1 w34 0 w34 1 w34 0 w34 1 w34 0 w29 1 w29 1 w29 0 w29 1 w29 0 w29 0 w21 1 w21 0 w21 1 w21 0 w21 1 w21 1 w20 1 w24 0 w24 1 w31 0 w8 1 w24 0 w30 1 w12 0 w17 0 w31 1 w17 1 w4 0 w4 0 w4 1 w2 0 w2 1 w2 0 w14 1 w14 0 w8 0 w8 1 w22 0 w22 1 w26 0 w26 1 w26 0 w26 1 w25 0 w25 1 w25 0 w25 0 w19 1 w19 0 w19 1 w19 0 w5 1 w5 0 w5 0 w11 1 w11 0 w11 0 w13 1 w13 0 w13 1 w10 0 w10 1 w10 0 w10 0 w9 1 w9 0 w9 0 w27 0 w27 1 w27 0 w27 1 w27 0 w16 1 w16 0 w16 1 w16 0 w3 1 w3 0 w3 1 w3 1 w3 0 w3 1 w6 0 w6 1 w6 1 w7 0 w7 1 w7 0 True\n",
      "GeneraciÃ³n 7: w39 1 w36 1 w36 0 w25 0 w36 1 w36 w37 0 w39 0 w35 1 w13 0 w27 1 w7 0 w35 1 w40 0 True\n",
      "GeneraciÃ³n 8: 1 w36 w39 1 w37 1 w39 0 w36 0 w36 1 w36 0 w36 0 w40 1 w35 0 w36 1 w37 0 w35 1 w36 0 w36 1 w36 0 w35 0 w35 1 w36 0 w35 1 w35 0 w35 1 w33 0 w33 1 w33 0 w33 1 w33 0 w33 1 w34 0 w34 1 w34 0 w34 1 w29 0 w34 1 w29 1 w34 1 w34 0 w29 0 w29 0 w29 1 w29 1 w29 1 w29 0 w29 1 w21 1 w21 0 w21 0 w21 0 w21 1 w21 0 w21 1 w21 1 w21 1 w21 1 w21 0 w24 0 w24 1 w24 1 w24 0 w24 1 w24 1 w24 0 w24 1 w24 0 w24 0 w24 0 w24 1 w30 0 w30 1 w30 0 w30 1 w30 0 w30 1 w30 0 w30 0 w30 0 w30 1 w23 1 w23 0 w23 0 w23 1 w23 0 w23 0 w23 1 w4 0 w32 0 w32 0 w32 1 w32 0 w12 1 w40 1 0 w19 0 w32 1 w32 0 w5 1 w5 0 w11 1 w11 0 w13 1 w13 0 w10 0 w10 1 w9 0 w9 0 w9 1 w27 0 w27 1 w27 0 w16 0 w16 1 w16 0 w3 1 w3 0 w3 1 w3 1 w3 0 w6 0 w6 1 w7 0 w7 1 w7 0 True True True\n",
      "GeneraciÃ³n 9: w17 1 w22 1 w39 1 w11 0 w40 0 w36 1 w13 0 w37 1 w39 0 w36 0 w37 1 w37 0 w42 0 w37 0 True\n",
      "GeneraciÃ³n 10: w37 1 w37 w37 1 w39 1 w36 0 0 w39 1 w37 0 w20 1 w36 0 w42 0 w37 1 w36 0 w36 1 w37 0 w36 0 w36 1 w35 1 w35 0 w37 1 w36 1 w39 0 w36 1 w35 0 w35 1 w36 0 w37 1 w36 0 w35 1 w35 0 w17 1 w12 0 w17 1 w1 0 w1 1 w31 0 w31 1 w4 1 w4 0 w4 1 w2 0 w2 1 w2 0 w14 1 w14 0 w8 0 w8 1 w8 0 w22 1 w22 0 w26 0 w26 1 w26 0 w26 1 w15 0 w15 0 w25 1 w25 0 w19 1 w19 0 w19 1 w19 0 w5 1 w5 0 w11 1 w11 0 w11 0 w13 1 w13 0 w10 1 w10 0 w10 1 w9 0 w9 0 w9 1 w27 0 w27 1 w27 0 w16 1 w16 0 w16 1 w16 0 w3 1 w3 0 w3 1 w3 0 w3 0 w7 1 w6 0 w7 1 w7 0 True w7 0 w7 1 True\n",
      "GeneraciÃ³n 11: w36 1 w36 1 w36 1 w35 0 w36 0 w35 0 w35 1 w35 0 w35 1 w35 0 w35 1 w33 0 w33 1 w33 0 w33 0 w33 1 w33 1 w33 0 w33 0 w34 1 w34 0 w34 1 w34 0 w34 1 w34 0 w34 1 w29 0 w29 1 w29 1 w29 1 w29 0 w29 1 w21 0 w21 1 w21 0 w21 1 w21 0 w21 1 w21 0 w24 1 w24 1 w24 0 w24 0 w24 1 w24 0 w30 1 w30 1 w30 0 w30 1 w30 1 w30 0 w23 0 w30 1 w23 0 w23 1 w23 0 w32 1 w32 0 w32 1 w20 0 w20 0 w20 1 w28 0 w28 1 w28 0 w12 1 w12 0 w18 0 w18 1 w18 1 w17 0 w17 0 w17 1 w17 0 w1 1 w1 0 w1 1 w31 0 w31 1 w31 0 w4 0 w4 1 w4 0 w4 1 w2 0 w2 1 w2 0 w2 0 w14 1 w14 0 w8 1 w8 0 w8 1 w22 0 w22 1 w22 0 w26 0 w26 1 w26 0 w15 1 w15 1 w15 0 w25 0 w25 1 w25 0 w19 0 w19 1 w19 0 w19 1 w5 0 w5 1 w5 0 w11 0 w11 1 w13 0 w13 1 w13 0 w10 1 w10 0 w10 1 w10 0 w9 0 w9 1 w9 0 w27 1 w27 0 w27 1 w16 0 w16 1 w16 0 w16 1 w3 0 w3 1 w3 0 w3 1 w3 0 w6 0 w6 1 w6 0 w6 0 w7 1 w7 1 w7 0 True\n",
      "GeneraciÃ³n 12: w39 w39 w40 1 w36 1 w36 0 w35 0 w39 1 w11 0 w40 1 w36 0 w35 0 w39 1 w37 0 w35 1 w35 0 w36 1 w35 0 w35 1 w35 0 w35 0 w33 1 w35 0 w33 1 w33 0 w33 1 w33 0 w34 1 w34 0 w34 1 w34 0 w34 1 w34 0 w34 1 w34 0 w29 1 w29 0 w29 1 w29 0 w29 1 w29 0 w29 1 w21 0 w21 1 w21 0 w21 1 w21 1 w21 1 w21 0 w24 0 w24 1 w24 1 w24 0 w24 1 w24 0 w30 1 w24 0 w30 0 w30 1 w30 1 w30 0 w30 0 w30 1 w23 0 w23 1 w23 0 w23 1 w32 0 w32 0 w18 1 w32 0 w20 1 w20 0 w20 0 w20 1 w28 1 w20 0 w28 1 w28 0 w12 1 w12 0 w18 1 w18 0 w18 0 w18 1 w17 0 w17 0 w17 1 w1 0 w1 1 w1 0 w5 1 w1 0 w31 1 w31 1 w4 0 w4 0 w4 1 w2 0 w4 1 w2 0 w14 0 w2 1 w14 0 w8 1 w14 1 w8 0 w8 0 w22 1 w8 0 w8 0 w22 1 w26 0 w22 1 w26 0 w26 0 w15 1 w15 0 w26 1 w15 0 w25 1 w25 0 w19 0 w19 0 w19 1 w19 0 w5 1 w5 0 w5 0 w5 1 w11 0 w11 1 w13 0 w13 1 w13 0 w13 1 w13 0 w10 0 w10 1 w10 0 w9 0 w9 1 w27 0 w27 0 w27 1 w27 0 w16 1 w16 0 w16 1 w16 0 w3 1 w3\n",
      "GeneraciÃ³n 13: w36 1 w39 1 w40 1 w39 0 w37 1 w36 0 w36 1 w39 0 w40 0 w37 0 w37 1 w37 0 w35 1 w37 0 w36 1 w39 0 w42 1 w36 1 w36 0 w42 0 w37 0 w36 1 w35 0 w35 1 w35 0 w36 1 w35 0 w35 1 w36 0 w33 1 w35 0 w33 1 w33 0 w33 1 w33 0 w33 1 w34 0 w33 1 w34 0 w27 1 w34 0 w12 1 w12 1 w17 0 w17 1 w1 0 w1 1 w31 0 w31 1 w4 1 w4 0 w4 1 w2 0 w2 1 w14 0 w14 0 w14 1 w8 0 w8 1 w22 1 w22 0 w22 1 w26 0 w26 1 w26 0 w26 0 w15 1 w15 0 w15 1 w25 0 w25 0 w25 1 w19 1 w19 0 w19 0 w19 1 w5 0 w5 1 w5 0 w11 0 w11 1 w11 0 w13 0 w13 1 w13 0 w10 1 w10 0 w10 1 w10 1 w10 0 w9 0 w9 1 w27 0 w27 0 w27 1 w27 0 w27 1 w16 0 w16 1 w16 0 w16 1 w16 0 w3 1 w3 0 w3 1 w3 0 w6 1 w3 0 w6 1 w6 1 w6 0 w7 1 w7 0 True\n",
      "GeneraciÃ³n 14: w35 1 w37 1 w37 1 w40 0 w36 0 w37 1 w39 0 w37 0 w37 1 w40 0 w36 1 w37 0 w35 0 w42 1 w36 0 w36 1 w35 0 w33 1 w37 0 w35 1 w35 0 w35 1 w35 0 w35 1 w33 0 w33 1 w33 0 w33 1 w34 0 w34 1 w34 0 w33 1 w34 0 w34 1 w34 0 w34 1 w34 1 w29 1 w34 0 w29 1 w29 0 w29 1 w29 1 w29 1 w29 1 w29 0 w29 1 w29 1 w21 0 w21 1 w21 0 w21 1 w21 1 w21 1 w21 1 w21 0 w21 0 w24 0 w24 0 w24 1 w24 0 w24 1 w24 0 w24 0 w24 1 w24 1 w24 1 w5 1 w30 0 w30 1 w30 0 w30 0 w30 0 w30 1 w30 0 w23 0 w30 1 w23 0 w23 0 w23 1 w29 1 w23 0 w23 1 w16 0 w23 1 w32 0 w32 0 w32 1 w19 0 w11 1 w11 0 w31 0 w11 0 w11 1 w11 0 w13 1 w10 0 w10 0 w9 1 w9 0 w9 0 w27 1 w27 0 w27 1 w16 0 w16 1 w16 0 w3 1 w3 1 w3 0 w3 1 w3 0 w6 1 w6 0 w7 1 w7 0 w7 1 w7 1 True True\n",
      "GeneraciÃ³n 15: w35 1 w36 1 w36 1 w40 0 w37 0 w37 1 w37 1 w36 0 w35 1 w39 0 w39 1 w37 0 w37 1 w37 0 w35 1 w35 0 w36 1 w35 1 w35 0 w33 0 w35 1 w35 1 w33 0 w35 1 w33 0 w33 1 w33 0 w33 1 w33 0 w34 1 w34 1 w34 0 w34 0 w34 1 w29 0 w34 1 w29 1 w29 1 w29 0 w29 1 w29 0 w29 1 w21 0 w21 1 w21 0 w21 0 w21 1 w21 1 w21 0 w24 1 w21 1 w21 1 w21 0 w24 1 w24 1 w24 0 w24 0 w24 1 w24 0 w24 1 w30 0 w30 1 w30 0 w30 1 w30 0 w23 0 w30 1 w23 0 w23 1 w23 0 w23 0 w23 0 w23 1 w32 0 w32 1 w32 0 w32 0 w20 1 w20 0 w20 1 w20 0 w20 1 w28 0 w19 0 w20 1 w19 0 w18 1 w28 0 w18 1 w24 0 w18 1 w18 0 w18 1 w40 0 w22 0 0 w17 1 w17 1 w17 0 w17 1 w37 1 w30 0 1 w37 0 w6 0 w11 1 0 w40 0 w10 1 w9 0 w9 1 w27 0 w27 1 w27 0 w16 1 w16 0 1 w3 0 w3 1 w3 0 w3 1 w6 0 w6 1 w6 0 w6 1 w7 1 w7 0 True\n",
      "GeneraciÃ³n 16: w35 1 w39 0 w36 1 w39 1 w36 0 w36 0 w35 0 w40 1 w35 1 w35 0 w39 1 w37 0 w40 1 w39 0 w36 1 w40 0 w33 1 w35 0 w35 0 w33 1 w33 0 w33 1 w34 0 w34 1 w34 0 w34 1 w29 0 w34 1 w29 0 w34 1 w29 0 w29 1 w29 0 w29 1 w21 0 w21 1 w21 0 w21 1 w21 0 w24 1 w24 0 w24 1 w24 1 w24 1 w30 0 w30 1 w30 0 w30 0 w23 1 w23 1 w23 0 w32 0 w32 1 w32 0 w20 1 w20 0 w20 1 w28 0 w28 1 w12 0 w12 1 w18 0 w18 1 w18 0 w17 1 w17 1 w17 0 w1 1 w1 0 w31 1 w31 0 w31 1 w4 0 w4 1 w4 0 w2 0 w2 1 w14 0 w14 1 w14 1 w14 0 w8 0 w8 1 w8 0 w22 1 w22 0 w26 0 w26 1 w26 0 w26 0 w15 1 w15 0 w25 0 w25 1 w25 0 w25 1 w19 0 w19 1 w19 0 w5 0 w5 1 w5 0 w11 0 w11 1 w11 0 w13 1 w13 0 w13 1 w10 0 w10 0 w10 1 w10 0 w9 0 w9 1 w9 0 w27 0 w27 1 w27 0 w27 1 w16 0 w16 1 w16 1 w16 0 w16 0 w3 1 w3 0 w3 1 w3 0 w6 1 w6 0 w6 0 w7 1 w7 0 w7 1 w7 0 True\n",
      "GeneraciÃ³n 17: w40 1 w36 1 w40 1 0 w39 0 w39 w37 w37 1 w37 0 w36 1 w36 w37 0 w39 1 w36 0 w36 1 w40 0 w33 1 w36 0 w35 1 w36 0 w33 1 w37 0 w36 0 w35 1 w35 0 w35 1 w35 0 w33 1 w33 0 w35 1 w34 0 w33 1 w33 0 w33 1 w34 0 w33 1 w33 0 w33 1 w34 0 w34 1 w34 0 w34 1 w34 0 w34 1 w34 0 w34 0 w29 1 w29 1 w29 1 w32 0 w20 1 w29 0 w28 1 w12 0 w12 1 w18 1 w17 0 w17 1 w1 0 w31 1 w31 0 w31 1 w4 0 w4 1 w2 0 w2 1 w14 0 w14 1 w14 1 w14 0 w8 1 w8 0 w22 0 w22 1 w26 0 w26 1 w26 0 w26 0 w15 1 w15 0 w25 1 w25 0 w25 1 w19 0 w19 0 w19 1 w19 0 w5 0 w5 1 w5 0 w11 1 w11 0 w11 0 w13 1 w13 0 w13 1 w10 0 w10 0 w10 1 w9 0 w9 0 w9 1 w27 0 w27 1 w27 0 w27 1 w16 0 w16 1 w16 0 w16 1 w16 1 w16 0 w3 1 w3 0 w3 1 w3 0 w3 1 w6 0 w6 1 w6 1 w7 0 w7 1 w7 0 True\n",
      "GeneraciÃ³n 18: w35 1 w36 1 w39 1 w36 1 w36 0 w37 0 w36 1 w37 1 w36 0 w35 0 w36 1 w36 0 w35 0 w35 1 w35 1 w35 0 w33 1 w35 0 w33 1 w33 0 w33 0 w35 1 w33 0 w33 1 w34 0 w34 1 w34 0 w34 1 w34 0 w34 1 w34 1 w34 1 w29 0 w29 1 w29 0 w29 1 w29 0 w29 1 w21 0 w21 0 w21 1 w21 1 w21 0 w21 1 w21 1 w24 1 w24 0 w24 1 w24 0 w24 0 w24 1 w30 1 w30 0 w30 1 w30 0 w30 0 w30 0 w23 1 w23 1 w23 0 w23 1 w32 0 w32 0 w32 0 w32 1 w20 1 w20 0 w20 1 w28 0 w28 1 w28 0 w28 0 w12 1 w12 0 w12 0 w12 1 w18 0 w18 1 w18 0 w17 1 w17 0 w17 1 w1 0 w1 1 w1 0 w1 0 w31 1 w31 1 w31 0 w4 1 w4 0 w4 1 w2 0 w4 1 w2 0 w2 1 w2 0 w2 0 w8 1 w14 0 w8 1 w8 0 w8 0 w8 1 w8 0 w22 1 w22 0 w22 1 w26 0 w26 0 w15 1 w15 0 w15 1 w15 0 w25 0 w25 1 w25 1 w19 0 w19 0 w19 1 w5 0 w5 0 w5 1 w5 0 w11 1 w11 0 w13 1 w13 0 w13 1 w13 0 w10 1 w10 0 w10 1 w10 0 w9 0 w9 1 w9 0 w27 1 w27 0 w27 0 w16 1 w16 1 w16 0 w16 1 w3 0 w3 1 w3 0 w3 1 w6 0 w6\n",
      "GeneraciÃ³n 19: w37 1 w37 1 w37 1 1 w36 0 w36 0 w39 1 w14 0 w36 1 w36 0 w39 1 w37 0 w36 1 w35 0 w35 0 w40 1 w36 0 w36 1 w36 0 w35 1 w35 0 w35 1 w39 1 w36 0 w6 0 w35 1\n",
      "GeneraciÃ³n 20: w39 1 w36 1 w40 1 w36 0 w36 0 w36 1 w36 0 w37 0 w36 0 w35 0 w39 1 w39 0 w35 1 w39 0 w39 1 w40 0 w36 1 w36 0 w42 0 w37 1 w36 0 w36 1 w36 0 w35 1 w35 0 w35 1 w35 0 w35 1 w33 0 w33 1 w35 0 w33 1 w35 0 w34 1 w33 0 w34 1 w33 1 w34 0 w33 0 w34 1 w34 0 w34 1 w33 1 w34 1 w34 1 w29 0 w29 1 w29 0 w20 1 w29 0 w26 1 w12 0 w27 0 w12 1 w23 0 1 w27 0 w17 1 1 w21 0 1 w39 1 w23 0 w31 0 w4 1 w18 1 w14 0 w32 0 w2 1 w14 0 w14 1 w8 0 w22 1 w22 0 w22 1 w26 0 w26 0 w26 1 w26 0 w15 1 w15 0 w25 1 w25 0 w25 0 w25 1 w19 0 w19 1 w19 0 w5 1 w5 0 w5 0 w11 1 w11 0 w13 0 w13 1 w13 0 w10 1 w10 0 w10 1 w9 0 w9 1 w9 0 w27 0 w27 1 w27 0 w27 1 w27 0 w16 1 w16 0 w16 1 w16 0 w3 1 w3 0 w3 1 w3 0 w3 1 w6 0 w6 0 w6 1 w7 0 w7 1 w7 0 True\n"
     ]
    }
   ],
   "source": [
    "model_charged.eval()\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_charged.to(device)\n",
    "\n",
    "# 1) Prompt y tokenizaciÃ³n inicial\n",
    "prompt = \"[BOS]\"\n",
    "inputs = fast_tokenizer(prompt, return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"].to(model_charged.device)\n",
    "attention_mask = inputs[\"attention_mask\"].to(model_charged.device)\n",
    "\n",
    "# 2) Tensor de condiciÃ³n (batch_size=1)\n",
    "reward_tensor     = torch.tensor([180/200], device=model_charged.device)  # normalizado\n",
    "prob_fault_tensor = torch.tensor([1], device=model_charged.device)\n",
    "\n",
    "# reward_tensor = torch.tensor([190/200]) \n",
    "# prob_fault_tensor = torch.tensor([0.8])\n",
    "\n",
    "# 3) GeneraciÃ³n\n",
    "outputs = model_charged.generate(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    reward=reward_tensor,        # aquÃ­ pasas tu condiciÃ³n\n",
    "    prob_fault=prob_fault_tensor,\n",
    "    max_length=300,\n",
    "    do_sample=True,\n",
    "    temperature=1.0,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=20,\n",
    ")\n",
    "\n",
    "# 4) Decodificar\n",
    "for i, out in enumerate(outputs):\n",
    "    text = fast_tokenizer.decode(out, skip_special_tokens=True)\n",
    "    print(f\"GeneraciÃ³n {i+1}:\", text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
